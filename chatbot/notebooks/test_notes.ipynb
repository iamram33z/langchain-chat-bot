{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Import Other Libraries\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUGGING_FACE_API: Qwen/QwQ-32B\n"
     ]
    }
   ],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set Environment Variables\n",
    "HUGGING_FACE_API = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# Print Environment Variables\n",
    "print(f\"HUGGING_FACE_API: {HUGGING_FACE_API}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model URLs\n",
    "Qwen = \"Qwen/QwQ-32B\"\n",
    "SentenceTransformer = \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Thread: Test prompt\n",
      "\n",
      "  1. Senior Member\n",
      "    Join Date\n",
      "    Dec 1969\n",
      "    Posts\n",
      "    1,229\n",
      "\n",
      "    ## Test prompt\n",
      "\n",
      "    I have a form that has a text box and a submit button. When the user clicks the submit button, I want to check if the text box is empty. If it is, I want to prompt the user to enter a value. If they click \"OK\" on the prompt, I want to return them to the form so they can enter a value. If they click \"Cancel\", I want to exit the page. I have the following code, but it doesn&#039;t work. What am I doing wrong? <BR><BR>function checkForm() {<BR> if (document.form1.txtSearch.value == \"\") {<BR> var answer = prompt(\"Please enter a search value.\", \"\");<BR> if (answer == null) {<BR> window.close();<BR> }<BR> else {<BR> document.form1.txtSearch.value = answer;<BR> return true;<BR> }<BR> }<BR> else {<BR> return true;<BR> }<BR>}<BR><BR>Then in the form tag, I have onSubmit=\"return checkForm()\"<BR><BR>Thanks.\n",
      "\n",
      "  2. Senior Member\n",
      "    Join Date\n",
      "    Dec 1969\n",
      "    Posts\n",
      "    1,229\n",
      "\n",
      "    ## RE: Test prompt\n",
      "\n",
      "    I think I figured it out. I need to set the value of the text box to the answer, then resubmit the form. So, after setting the value, I need to do document.form1.submit(); instead of return true. But then, how do I handle the case where the user clicks \"Cancel\"? Because if I do window.close(), that would close the window, but if it&#039;s not a pop-up window, that would close the browser. So maybe I should just return false in that case. Hmm. Let me think. Let me try to rework the code.\n",
      "\n",
      "  3. Senior Member\n",
      "    Join Date\n",
      "    Dec 1969\n",
      "    Posts\n",
      "    1,229\n",
      "\n",
      "    ## RE: Test prompt\n",
      "\n",
      "    Here is the revised code. It works now. <BR><BR>function checkForm() {<BR> if (document.form1.txtSearch.value == \"\") {<BR> var answer = prompt(\"Please enter a search value.\", \"\");<BR> if (answer == null) {<BR> return false;<BR> }<BR> else {<BR> document.form1.txtSearch.value = answer;<BR> document.form1.submit();<BR> }<BR> }<BR> else {<BR> return true;<BR> }<BR>}<BR><BR>So, if the user clicks \"Cancel\", the form doesn&#039;t submit. If they click \"OK\", the form is submitted. If the text box already has a value, the form is submitted. So that works. But I have to have the onSubmit=\"return checkForm()\".<BR><BR>But I wonder if there is a better way. For example, if the user clicks \"OK\" and enters a value, then the form is submitted. But if they click \"Cancel\", then the form is not submitted. So that works. But in the first case, when the user enters a value, the form is submitted. But in the second case, when the user enters a value, the form is submitted again. Wait, no. Let me see. The first time, the user clicks submit, but the text box is empty. So the prompt comes up. They enter a value and click OK. Then the value is set, and the form is submitted. So that works. If they click Cancel, then the form is not submitted. So that works. If the text box already has a value, then the form is submitted. So that works. So this code works. But I wonder if there is a better way. Maybe using a confirm box instead of a prompt? But the user has to enter a value. So prompt is better. So this works. So I think this is okay.\n",
      "\n",
      "#### Posting Permissions\n",
      "\n",
      "  • You may not post new threads\n",
      "  • You may not post replies\n",
      "  • You may not post attachments\n",
      "  • You may not edit your posts\n",
      "  •\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(token=\"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\")\n",
    "response = client.text_generation(\"Test prompt\", model=\"Qwen/QwQ-32B\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HuggingFace LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=Qwen,\n",
    "    model_kwargs={\"huggingface_api_key\": HUGGING_FACE_API},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication failed: Invalid user token.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "try:\n",
    "    user_info = api.whoami(token=HUGGING_FACE_API)\n",
    "    print(\"Authentication successful! User Info:\", user_info)\n",
    "except Exception as e:\n",
    "    print(\"Authentication failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize HuggingFace Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=SentenceTransformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize Output Parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF File Path: /workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf\n"
     ]
    }
   ],
   "source": [
    "# Print PDF file path\n",
    "pdf_file_path = os.path.join(os.path.dirname(os.getcwd()), \"data/codeprolk.pdf\")\n",
    "print(\"PDF File Path:\", pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF File\n",
    "loader = PyPDFLoader(\"/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf\")\n",
    "\n",
    "# Load documents from the PDF\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 20\n"
     ]
    }
   ],
   "source": [
    "# Initialize Text Splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents into smaller chunks\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the number of chunks created\n",
    "print(f\"Number of chunks created: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS vector store from the texts\n",
    "vectorstore = FAISS.from_documents(documents=texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template for the LLM\n",
    "prompt_template =\"\"\"\n",
    "    You are a helpful assistant. Answer the question based on the provided context.\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "\n",
    "# Create the prompt from the template\n",
    "prompt = ChatPromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the question and pass it to the retriever\n",
    "def retrieve_context(input_dict):\n",
    "    question = input_dict[\"question\"]\n",
    "    context = retriever.invoke(question)\n",
    "    print(f\"Retrieved context: {context}\")  # Check the context being passed\n",
    "    return context\n",
    "\n",
    "# Update the chain\n",
    "chain = (\n",
    "    {\"context\": RunnableLambda(retrieve_context), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context: [Document(id='f2bbcd5c-5744-43e9-b8ce-7aa5caf49b75', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-06-18T10:00:42+05:30', 'author': 'Dinesh Piyasamara', 'moddate': '2024-06-18T10:00:42+05:30', 'source': '/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='Partnerships and Collaborations \\nCodePRO LK is exploring partnerships with educational institutions, tech companies, and \\nindustry experts to enrich its content and provide learners with access to a broader range of \\nresources and opportunities. These collaborations aim to bridge the gap between education and \\nindustry, ensuring that learners are well-prepared for real-world challenges.'), Document(id='6b5cf807-d40f-46bc-aacb-5b44cf13b4b9', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-06-18T10:00:42+05:30', 'author': 'Dinesh Piyasamara', 'moddate': '2024-06-18T10:00:42+05:30', 'source': '/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='Community and Support \\nCodePRO LK has cultivated a vibrant community where learners can interact, share insights, and \\nsupport each other. Additionally, the platform offers consultation services for personalized \\nlearning support. \\n \\nCodePRO LK YouTube Channel \\nOverview \\nThe CodePRO LK YouTube Channel is a crucial extension of the platform, providing a wealth'), Document(id='47d6f9a4-f8ba-4443-b676-1a251ec272f8', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-06-18T10:00:42+05:30', 'author': 'Dinesh Piyasamara', 'moddate': '2024-06-18T10:00:42+05:30', 'source': '/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='Community Engagement and Events \\nCodePRO LK is committed to strengthening its community through regular engagement \\nactivities such as webinars, live coding sessions, hackathons, and tech talks. These events \\nprovide valuable networking opportunities and practical experience, fostering a supportive and \\ncollaborative learning environment. \\n \\nConclusion'), Document(id='b52b130b-d5e2-43bd-9f13-ab70f3ff1d7f', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2024-06-18T10:00:42+05:30', 'author': 'Dinesh Piyasamara', 'moddate': '2024-06-18T10:00:42+05:30', 'source': '/workspaces/langchain-chat-bot/chatbot/data/codeprolk.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='best aiya.\" \\n• Heshan R: \"Great work brother. I was scared of coding before I attended this course. \\nHowever, you taught us A-Z in Python. Thanks again for volunteering for such a thing. \\nGood luck.❤\" \\nThese testimonials highlight the significant positive impact CodePRO LK has had on its learners, \\nhelping them overcome challenges and achieve their educational and professional goals.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/langchain-chat-bot/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  CodePRO LK is an educational platform focused on teaching programming and technology skills. It offers resources, courses, and community support to help learners gain practical experience and prepare for real-world challenges. The platform collaborates with educational institutions and tech companies, hosts events like webinars and hackathons, and provides a supportive community environment. Learners have praised its effectiveness in making coding accessible and enjoyable.\n",
      "\n",
      "Assistant: \n",
      "\n",
      "The user's question asks about \"codeprolk,\" and the context provided contains information about an organization named CodePRO LK. The context describes CodePRO LK as an educational platform offering programming courses, community support, partnerships with institutions, and events such as webinars and hackathons. Testimonials from learners praise its effectiveness in teaching skills like Python. The answer should synthesize these points to clearly define CodePRO LK based on the given context.\n",
      "\n",
      "**Answer:**  \n",
      "CodePRO LK is an educational initiative that provides programming and technology training to help learners develop practical skills and prepare for real-world challenges. It offers courses, community support through forums and consultations, and collaborates with educational institutions and tech companies to enhance its resources. The platform also hosts events like webinars, hackathons, and live coding sessions to foster learning and networking. Learners have praised CodePRO LK for making coding accessible and effective, with testimonials highlighting its success in teaching foundational to advanced skills, such as Python, and building confidence in participants.  \n",
      "\n",
      "---  \n",
      "This answer combines details from the provided documents about CodePRO LK's educational focus, community engagement, partnerships, events, and positive learner feedback to comprehensively address the question. The name \"codeprolk\" is likely a misspelling or shorthand for \"CodePRO LK,\" which is the organization described in the context. No direct mention of an individual named \"codeprolk\" exists; instead, the platform is the subject of the information. The author of the documents is Dinesh Piyasamara, but there's no indication they are \"codeprolk\" themselves. The response thus focuses on the organization rather than an individual.  \n",
      "\n",
      "If further clarification is needed, additional context about an individual associated with CodePRO LK might be required, but based on the provided information, the focus remains on the platform.  \n",
      "\n",
      "---  \n",
      "**Final Answer**  \n",
      "CodePRO LK is an educational platform dedicated to teaching programming and technology skills through courses, community support, and partnerships with educational institutions and industry experts. It offers events like webinars and hackathons, a vibrant\n"
     ]
    }
   ],
   "source": [
    "# Invoke RAG Chain with a sample question\n",
    "response = chain.invoke({\"question\": \"who is codeprolk?\"})\n",
    "\n",
    "# Print the response\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
